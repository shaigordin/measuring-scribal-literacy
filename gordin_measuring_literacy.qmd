---
title: "Measuring Scribal Literacy Through Quantitative Analysis"
subtitle: "A Landmark-Based Approach to Cuneiform Signs"
location-date: "17–19 September 2025, Ghent and Brussels"
event: "Bytes and Bygones – Digital and Computational Analyses of Ancient Cultures (DANES25)"
authors:
  - name: "Shai Gordin"
    url: "https://digitalpasts.github.io/"
    orcid: "0000-0002-8359-382X"
    affiliation:
      - Ariel University
      - Open University of Israel
title-slide-attributes:
  data-background-image: img/clay_background.jpg
  data-background-opacity: "0.3"
format:
  revealjs:
      slide-number: true
      progress: false
      preview-links: true
      theme: [default, scss/style.scss]
      width: 1600
      height: 900
      transition: fade
      citeproc: true
      citations-hover: true
      bibliography: bib/cuneimorph.bib
      csl: bib/journal-of-archaeological-research.csl
      link-external-icon: false
      link-external-newwindow: true
      embed-resources: false
      multiplex: false
      pdf-separate-fragments: true
      tbl-cap-location: bottom
      template-partials:
        - templates/title-slide.html
---

# Measuring Scribal Literacy

::: {.absolute top="0" left="95%"}
::: sectionhead
1 [2 3 4 5]{style="opacity:0.25"}
:::
:::

---

## Talk Overview

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
1 [2 3 4 5]{style="opacity:0.25"}
:::
:::

::: {.columns}

::: {.column width="70%"}
- Deeplomatics: Transmission of Cuneiform from Centre to Periphery
- Qualitative Descriptions as Baselines for (Statistical) Measurements
- Protosnap: Using Generative AI for Measuring Sign Gestalt
- Geometric-Morphometrics (GMM) for Sign Shape Analysis
- State of the Project and Future Outlook
:::

::: {.column width="30%"}

<br>

![Scan and follow the presentation online!](img/qr_code.webp){fig-align="center"}
:::

:::

---


## Diplomatics Background

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
1 [2 3 4 5]{style="opacity:0.25"}
:::
:::

::: {.columns}

::: {.column width="40%"}
::: {.fragment fragment-index=1 .fade-in-then-semi-out}
- Verify the authenticity of traditional compositions
- Legal authority of institutional and archival records
- Consistent use of document features to establish age
:::
:::
:::

---

## Cuneiform Deeplomatics: Research Questions

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
1 [2 3 4 5]{style="opacity:0.25"}
:::
:::

::: {.columns}

::: {.column width="40%"}
- How to detect and measure which shape features make scribal habits distinguishable?
- Which computational methods allow us to analyse these shapes over the longue durée (i.e. at scale)?
- Can we generalise and generate a typical tablet and its script from a given period / genre / scribal school?

-> A "copilot" historian: answers need to be explainable, no black-boxes
:::
:::
::: {.column width="60%"}
![After @Liverani2003](img/south_levant_ia2.webp){fig-align="center" width="95%"}
:::
:::

---

## Writing proficiency: The Case of Peripheral Cuneiform

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
1 [2 3 4 5]{style="opacity:0.25"}
:::
:::

::: {.columns}

::: {.column width="40%"}
- How proficient are peripheral scribes?
- Is the trajectory of the spread of cuneiform from Mesopotamia to the west retraceable using palaeography?
- Peripheral Archives: Hattusa, Alalakh, Ugarit
- Mesopotamian Archive (control group): MA Assur
- Legal genres: signed, dated, verified(?)


::: {.body-smaller}

| City  | Text Group   |  Dates  |
|-------------- | -------------- |  -----------   |
| Hattusa    | Land grants     |     |
| Ugarit   | Legal texts    |     |
| Alalakh VII   | Legal texts     |     |
| Alalakh IV    | Legal texts     |     |
| Assur   | KAJ texts (Ebeling)     |     |
: After @Palmisano.etal2019; @Sharon2013

:::


:::

::: {.column width="60%"}
![](img/south_levant_ia2_assyria.webp){fig-align="center" width="95%"}
:::

:::

---

# Qualitative Descriptions as Baselines for (Statistical) Measurements

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1]{style="opacity:0.25"} 2 [3 4 5]{style="opacity:0.25"}
:::
:::

---

## Descriptive to Measurable Palaeography

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1]{style="opacity:0.25"} 2 [3 4 5]{style="opacity:0.25"}
:::
:::

::: {.columns}

::: {.column width="45%"}
- Gordin 2015: Comparing scribal hands and qualifying them
- Kryszeń 2025: Handwriting analysis, structural approach based on common sets of wedges
- Cammarosano 2014: Defining the geometry of the wedge (3D data)

:::

::: {.column width="50%"}

:::

:::

![](img/study_areas.webp){.absolute right="0%" top="15%" width="50%"}
![](img/gerda-henkel-logo.webp){.absolute right="0%" top="85%" width="25%"}
![](img/logo-unito.webp){.absolute right="24%" top="76%" width="15%"}
![](img/lmu_logo.webp){.absolute right="40%" top="83%" width="15%"}
![](img/radner.webp){.absolute left="5%" top="75%" width="12%"}
![](img/novotny.webp){.absolute left="25%" top="75%" width="12%"}


---

# Protosnap: Using Generative AI for Measuring Sign Gestalt

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2]{style="opacity:0.25"} 3 [4 5]{style="opacity:0.25"}
:::
:::

---

## The Research Question

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2]{style="opacity:0.25"} 3 [4 5]{style="opacity:0.25"}
:::
:::

::: {.columns}

::: {.column width="50%"}
- Can we use the structural consistency of cuneiform signs to identify deep image features and align them to a 2D image of a cuneiform sign?
- Creating a tablet handcopy: synthesizing sign features
- Extracting varied sign forms to create more artificial data, helps train OCR models
:::

::: {.column width="50%"}
![](img/rank_size_all_areas.webp){fig-align=center}
:::

:::

---

## Protosnap's Methods

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2]{style="opacity:0.25"} 3 [4 5]{style="opacity:0.25"}
:::
:::

::: {.columns}

::: {.column width="50%"}
- Stable Diffusion model trained specifically on cuneiform images for deep image understanding (SD)
- This allows recognition of wedge impressions even with varying lighting, damage, and material textures
- Deep diffusion features are used to find matches between prototype images (cuneiform fonts) and sign samples (“best buddy correspondences”)
- Two-step alignment
  - Global alignment: roughly positions the prototype over the photo
  - Local refinement: adjusts each wedge to its precise location on the tablet
- Match each prototype wedge to its impression in the tablet photo
:::

::: {.column width="50%"}
![](img/rank_size_all_areas.webp){fig-align=center}
:::

:::

---

## Protosnap's results

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2]{style="opacity:0.25"} 3 [4 5]{style="opacity:0.25"}
:::
:::

::: {.columns}

::: {.column width="50%"}

- Created a benchmark corpus: 272 images, 25 sign classes, with expert-annotated landmark points
- Compared expert labels to model predictions; Protosnap outperformed generic matching methods (F1 score: 27.14% vs. 16.14% at 20-pixel threshold)
- The task is challenging due to subjectivity and expert disagreement
- The model can generate accurate synthetic cuneiform signs, addressing the lack of labeled data—especially for rare variants
- Using synthetic data improved sign classification, especially for rare signs (accuracy: 53.17% vs. 25.84%)
- Method is period- and language-agnostic: works for any cuneiform language or era
- Demonstrated success on Hittite cuneiform, which the model had never seen before
- Next step: quantifying sign and wedge features in a manner interpretable for Assyriologists?

:::

::: {.column width="50%"}
![](img/rank_size_samaria.webp)
:::

:::

---

# Geometric-Morphometrics (GMM) for Sign Shape Analysis

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3]{style="opacity:0.25"} 4 [5]{style="opacity:0.25"}
:::
:::

---

## What is Geometric-Morphometrics (GMM)?

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3]{style="opacity:0.25"} 4 [5]{style="opacity:0.25"}
:::
:::

::: {.columns}

::: {.column width="50%"}
- GMM quantitatively analyzes shape using geometric coordinates (not just measurements)
- Shape is captured by placing landmarks (homologous points) on each object
- Variables are the cartesian coordinates of these landmarks
- Size is not included; the focus is on shape only
- Results can be visualized as images
- Several analysis variants exist (e.g., EDMA)
:::

:::

---

## GMM Workflow & Procrustes Superimposition

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3]{style="opacity:0.25"} 4 [5]{style="opacity:0.25"}
:::
:::

::: {.columns}

::: {.column width="48%"}
- Steps in GMM:
  - Collect landmark data (same number & order for all shapes)
  - Perform Procrustes superimposition to standardize shapes
  - Analyze shape similarity and difference
  - Procrustes superimposition:
    - Removes size, translation, and rotation
    - Aligns all shapes to a common coordinate system
    - Also called Procrustes analysis, GPA, or least squares fitting
    - Enables direct comparison of shape differences

Superimposing shapes to measure differences is a relatively recent method in morphometrics.
The Procrustes method, first used in multivariate statistics, was adapted for shape analysis.
The term “Procrustes” comes from Greek mythology: Procrustes forced victims to fit his bed by stretching or cutting them.
Similarly, Procrustes analysis fits and scales one shape onto another for comparison.

![](img/armep.webp){fig-align="center"}
:::

::: {.column width="50%"}
![](img/data_management.webp){fig-align="center" width="70%"}
:::

:::

---

## Definition of Wedge Geometry and Landmark Choice

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3]{style="opacity:0.25"} 4 [5]{style="opacity:0.25"}
:::
:::

::: {.columns}

::: {.column width="48%"}
- example photos of landmarks on cuneiform signs
:::

::: {.column width="50%"}
![](img/data_management.webp){fig-align="center" width="70%"}
:::

:::

---

# State of the Project and Future Outlook

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5
:::
:::

---

## The Pipeline

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5
:::
:::

::: {.columns}

::: {.column width="48%"}
- image of the pipeline
:::

::: {.column width="50%"}
![](img/data_management.webp){fig-align="center" width="70%"}
:::

:::

---

## Acquiring Data

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5
:::
:::

::: {.columns}

::: {.column width="48%"}
- NEED: Cropped and identified sign images (potentially in the hundreds or thousands)
- Approach:
  1. Get tablets and metadata:
    - High-quality PDF scans of books
    - Online images (CDLI, Hethithesches Portal)
    - Tablets that have not been photographed
  2. Crop signs -> eBL model (state-of-the-art, actively under development)
  3. Identify cropped signs -> Protosnap + eBL model + alignment with text editions (Denker et al.)
  4. Annotate Landmarks -> manually + Protosnap
:::

::: {.column width="50%"}
![](img/data_management.webp){fig-align="center" width="70%"}
:::

:::

---

## Issues with Getting Tablets

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5
:::
:::

::: {.columns}

::: {.column width="48%"}
- Quality of images from scanned books and in online databases is inconsistent
- Older images are from various angles, before tablet imaging was standardised
- Copyrights: How to save, where to publish
- A variety of web frameworks and protocols
- Standardizing metadata from various sources, including OCR'ed publications
:::

::: {.column width="50%"}
![](img/data_management.webp){fig-align="center" width="70%"}
:::

:::

---

## Cropping Signs

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5
:::
:::

::: {.columns}

::: {.column width="48%"}
- State-of-the-art eBL model: period agnostic, identifies locations of signs
- Additional code: line clustering
- Initial results on Hittite tablets were highly successful
- Cases where signs are already cropped in book publications, e.g. from Ugarit. Cropped signs were extracted from the PDF
:::

::: {.column width="50%"}
![](img/data_management.webp){fig-align="center" width="70%"}
:::

:::

---

## Identifying Signs

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5
:::
:::

::: {.columns}

::: {.column width="48%"}
- Pre-cropped signs already come with sign-readings
- eBL model can also be used to identify signs - however, not period agnostic, mostly trained on first millennium data (though work in progress!)
- Protosnap is the way to go! Creating artificial data to improve model's results
- Line identification allows alignment and validation against digital editions (Denker et al.)
:::

::: {.column width="50%"}
![](img/data_management.webp){fig-align="center" width="70%"}
:::

:::

---

## Annotating Landmarks

::: {.absolute top="0" left="95%"}
::: {.sectionhead}
[1 2 3 4]{style="opacity:0.25"} 5
:::
:::

::: {.columns}

::: {.column width="48%"}
- Techniques to annotate cropped images
- Choosing the "right" signs
- Landmarks vs. semi-landmarks
- Human error in annotation, subjectivity in how we perceive signs and wedges, changing angles of shadows in 2D images, error analysis
- Planning a DANES working group on computational palaeography, a place for discussion and group annotations!
:::

::: {.column width="50%"}
![](img/data_management.webp){fig-align="center" width="70%"}
:::

:::

---

{background-image="img/background.webp" background-opacity="15%" style="text-align:center"}

<br>

Shai Gordin ([shaigo@ariel.ac.il](mailto:shaigo@ariel.ac.il)) - {{< ai orcid >}} [0000-0002-8359-382X](https://orcid.org/0000-0002-8359-382X)

Digital Pasts Lab ([digpasts@gmail.com](mailto:digpasts@gmail.com))

<br>


![](img/qr_code.webp)
<br>
Presentation online at the qrcode above or at the following [link](https://www.andreatitolo.com/talks/2024-12-13-unito-empires-workshop/titolo_palmisano_tale_of_two_kingdoms.html)

<br>

 {{< ai zenodo >}} [https://doi.org/10.5281/zenodo.12011486](https://doi.org/10.5281/zenodo.12011486)

 {{< bi github >}} [Slides Source Code](https://github.com/UnitoAssyrianGovernance/evoa-2024) - [CC BY-SA-4.0](https://creativecommons.org/licenses/by-sa/4.0/)

# Bibliography
